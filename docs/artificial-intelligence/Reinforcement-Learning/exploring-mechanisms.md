---
title: 探索机制
tags:
  - 强化学习
---

## ε-greedy 探索策略

ε-greedy 探索策略 是强化学习中一种用于平衡 探索（exploration） 和 利用（exploitation） 的简单而有效的策略。在强化学习中，智能体面临的一个核心问题是：是否应该选择一个当前认为最优的行为（利用）还是尝试新的行为以获得更多关于环境的信息（探索）。

ε-greedy 策略的核心思想：

- 利用（Exploitation）：智能体根据当前的 Q 值估计，选择 Q 值最大的动作，也就是认为最优的动作。
- 探索（Exploration）：智能体随机选择动作，不考虑当前的 Q 值，目的是尝试新的动作，可能发现更优的选择。

ε-greedy 策略的关键点：

1. ε 的值：ε 通常在训练初期设置为较大的值，比如 1.0，表示智能体大部分时间都在进行探索。随着训练的进行，ε 会逐渐减小，使智能体更多地选择利用（即选择当前最优动作）。

2. 典型的衰减方式是：随着时间的推移或随着智能体在环境中学到更多信息，逐步将 ε 减小到接近 0。例如，训练初期 ε = 1.0，训练结束时 ε 可能降低到 0.1 或更低。探索和利用的平衡：

3. 在训练初期，智能体对环境的了解较少，因此需要更多的探索，增加发现最优策略的可能性。随着智能体对环境的了解逐步加深，ε 值减小，智能体会更多地选择当前的最优动作，从而提高整体表现。

## 参考

[强化学习中的探索机制](https://di-engine-docs.readthedocs.io/zh-cn/latest/02_algo/exploration_rl_zh.html)
